{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDY8LL0deEeOMeOTFk0k1A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leila828/DeepLearning_projects/blob/master/ResNet18_classification_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7gkjOWekeEu",
        "outputId": "a24e3b2e-0883-4389-990f-baea26afc427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.0+cu121\n"
          ]
        }
      ],
      "source": [
        "# prompt: how to test pytorch version\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: load cat & dogs dataset\n",
        "\n",
        "import torchvision\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsnLSkDJlTfn",
        "outputId": "62780b7b-dbb1-430e-de35-cdc9af325ac6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 68332710.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to recuperate dog and cats dataset and save it in dir\n",
        "\n",
        "import os\n",
        "\n",
        "def filter_dataset(dataset, class_names, target_dir):\n",
        "  os.makedirs(target_dir, exist_ok=True)\n",
        "  indices = [i for i, label in enumerate(dataset.targets) if dataset.classes[label] in class_names]\n",
        "  for i in indices:\n",
        "    img, label = dataset[i]\n",
        "    class_name = dataset.classes[label]\n",
        "    save_path = os.path.join(target_dir, class_name)\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    img.save(os.path.join(save_path, f'{i}.jpg'))\n",
        "\n",
        "filter_dataset(trainset, ['cat', 'dog'], 'cifar10_dogs_cats')\n"
      ],
      "metadata": {
        "id": "0AY_hC4Yl9bv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: do the salme for test data set\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=None)\n",
        "\n",
        "filter_dataset(testset, ['cat', 'dog'], 'cifar10_dogs_cats_test')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDz_3nJhmdz4",
        "outputId": "56b5e2bb-b5f8-4a5b-a5ef-9074d465b0ba"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_dir= './data/train'\n",
        "train_dataset = datasets.ImageFolder(root= train_dir,transform=transforms.ToTensor())\n",
        "print(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4758bbee-abf6-4873-baef-333cc7ae4c31",
        "id": "T_A_aoTWmiau"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 10000\n",
            "    Root location: ./data/train\n",
            "    StandardTransform\n",
            "Transform: ToTensor()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes= train_dataset.classes\n",
        "print(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8ecCOs7nQHN",
        "outputId": "afd64328-cedf-436c-cef7-23ef7e3801c7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cat', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_dataset.class_to_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UeyV0hqnUev",
        "outputId": "33c12873-1b55-4cea-f9a7-ebcc7a2df0c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cat': 0, 'dog': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: generate class BinaryCnn\n",
        "\n",
        "import torch.nn as nn\n",
        "\n",
        "class BinaryCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BinaryCNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "    self.relu1 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.flatten =nn.Flatten()\n",
        "    self.fc1 = nn.Linear(16 * 112 * 112, 1)\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool1(self.relu1(self.conv1(x)))\n",
        "    x = x.fc1(self.flatten(x))\n",
        "    x = self.sigmoid(self.fc2(x))\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "_ROn0CPenlRe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Instantiate a model from the CNNModel class and access the convolutional layers.\n",
        "# Create a new convolutional layer with in_channels equal to existing layer's out_channels, out_channels set to 32, and stride and padding both set to 1, and assign it to conv2.\n",
        "# Append the new layer to the model, calling it \"conv2\".\n",
        "\n",
        "# Instantiate the model\n",
        "model = BinaryCNN()\n",
        "\n",
        "# Access convolutional layers and retrieve out_channels of the last one\n",
        "last_conv_layer = model.conv1\n",
        "in_channels = last_conv_layer.out_channels\n",
        "\n",
        "# Create a new convolutional layer\n",
        "conv2 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "# Append the new layer to the model\n",
        "model.conv2 = conv2\n",
        "print(\"Extended model: \", model)\n"
      ],
      "metadata": {
        "id": "VTlkg4VRwPNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6709d8b-f54a-4b3a-9f1f-ef52ac3fbee4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extended model:  BinaryCNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=200704, out_features=1, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ModelCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ModelCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(32 * 56 * 56, 10) # Adjusted the input size based on two pooling layers\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "L2Lmi1HTQ4WY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Instantiate the model\n",
        "model = ModelCNN()\n",
        "\n",
        "# Access convolutional layers and retrieve out_channels of the last one\n",
        "last_conv_layer = model.conv1\n",
        "in_channels = last_conv_layer.out_channels\n",
        "\n",
        "# Create a new convolutional layer\n",
        "conv2 = nn.Conv2d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "# Append the new layer to the model\n",
        "model.conv2 = conv2\n",
        "print(\"Extended model: \", model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKh5anNBSPoQ",
        "outputId": "c8e64a3a-5a81-42fa-a52c-50c4d116ca8a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extended model:  ModelCNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=100352, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class ManufacturingCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ManufacturingCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(32 * 56 * 56, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "pTeK5fvzP4E6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "save a model with weights\n"
      ],
      "metadata": {
        "id": "7N-CJ5FcH1eI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), 'ModelCNN.pth')\n",
        "\n",
        "# Create a new model\n",
        "loaded_model = ManufacturingCNN()\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model.load_state_dict(torch.load('ModelCNN.pth'))\n",
        "print(loaded_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJd4-zZOH5mY",
        "outputId": "76cb92ff-2467-45ad-8f0e-61c52f1152cb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ManufacturingCNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu1): ReLU()\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (relu2): ReLU()\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=100352, out_features=10, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-2dacf206ee47>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_model.load_state_dict(torch.load('ModelCNN.pth'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading a pre-trained model"
      ],
      "metadata": {
        "id": "nf5BOBvZJ9AH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import resnet18 model\n",
        "from torchvision.models import resnet18,ResNet18_Weights\n",
        "\n",
        "# Initialize model with default weights\n",
        "weights = ResNet18_Weights.DEFAULT\n",
        "model = resnet18(weights=weights)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize the transforms\n",
        "transform =weights.transforms()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qR0Za8YKAFY",
        "outputId": "03439fe8-5829-4f98-88f9-4bdb37e8578a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 92.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image classification with ResNet"
      ],
      "metadata": {
        "id": "7MJuEULXOWcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Assuming 'weights' is your ResNet18_Weights object\n",
        "preprocess = weights.transforms()\n",
        "\n",
        "# Load an image using a library like PIL\n",
        "from PIL import Image\n",
        "img = Image.open('cat.jpeg')\n",
        "# Apply preprocessing transforms\n",
        "batch = preprocess(img).unsqueeze(0)\n",
        "\n",
        "# Apply model with softmax layer\n",
        "prediction = model(batch).squeeze(0).softmax(0)\n",
        "\n",
        "# Apply argmax\n",
        "class_id = prediction.argmax().item()\n",
        "score = prediction[class_id].item()\n",
        "category_name = weights.meta[\"categories\"][class_id]\n",
        "print(category_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRlF_ajeI0yZ",
        "outputId": "9a0b5334-298d-47af-e259-f7c99c1ed789"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Egyptian cat\n"
          ]
        }
      ]
    }
  ]
}