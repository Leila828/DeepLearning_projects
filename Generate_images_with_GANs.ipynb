{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtecZBVIPLYeV6eaxxWSK0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Leila828/DeepLearning_projects/blob/master/Generate_images_with_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator\n",
        "A GAN generator takes a random noise vector as input and produces a generated image. To make its architecture more reusable, you will pass both input and output shapes as parameters to the model. This way, you can use the same model with different sizes of input noise and images of varying shapes.\n",
        "\n",
        "You will find torch.nn imported already imported for you as nn. You can also access a custom gen_block() function which returns a block of: linear layer, batch norm, and ReLU activation. You will use it as a building block for the generator"
      ],
      "metadata": {
        "id": "vAU0wWltoKAa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ft4RxIAEnwFE"
      },
      "outputs": [],
      "source": [
        "def gen_block(in_dim, out_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_dim, out_dim),\n",
        "        nn.BatchNorm1d(out_dim),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "HJt7BB8ppeVy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        # Define generator block\n",
        "        self.generator = nn.Sequential(\n",
        "            gen_block(in_dim, 256),\n",
        "            gen_block(256, 512),\n",
        "            gen_block(512, 1024),\n",
        "          \t# Add linear layer\n",
        "            nn.Linear(1024, out_dim),\n",
        "            # Add activation\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "      \t# Pass input through generator\n",
        "        return self.generator(x)"
      ],
      "metadata": {
        "id": "dCzgVm9JoVBz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the generator defined, the next step in building a GAN is to construct the discriminator. It takes the generator's output as input, and produces a binary prediction: is the input generated or real?\n",
        "\n",
        "You will find torch.nn imported already imported for you as nn. You can also access a custom disc_block() function which returns a block of a linear layer followed by a LeakyReLU activation. You will use it as a building block for the discriminator."
      ],
      "metadata": {
        "id": "1SqjrTdqpmtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def disc_block(in_dim, out_dim):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(in_dim, out_dim),\n",
        "        nn.LeakyReLU(0.2)\n",
        "    )"
      ],
      "metadata": {
        "id": "vtrIrBfFoNsf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, im_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "            disc_block(im_dim, 1024),\n",
        "            disc_block(1024, 512),\n",
        "            # Define last discriminator block\n",
        "            disc_block(512,256),\n",
        "            # Add a linear layer\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define the forward method\n",
        "       return self.disc(x)"
      ],
      "metadata": {
        "id": "1R-eVP0NqsAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep convolutional Gans"
      ],
      "metadata": {
        "id": "T-Ypc3OXsNAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a convolutional generator following the DCGAN guidelines discussed in the last video.\n",
        "\n",
        "torch.nn has been pre-imported as nn for your convenience. Additionally, a custom function dc_gen_block() is available, which eturns a block of a transposed convolution, batch norm, and ReLU activation. This function serves as a foundational component for constructing the convolutional generator. You can get familiar with dc_gen_block()'s definition below."
      ],
      "metadata": {
        "id": "6vjYGXlnsSAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dc_gen_block(in_dim, out_dim, kernel_size, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_dim, out_dim, kernel_size, stride=stride),\n",
        "        nn.BatchNorm2d(out_dim),\n",
        "        nn.ReLU()\n",
        "    )"
      ],
      "metadata": {
        "id": "4Lq8-4VusVHd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DCGenerator(nn.Module):\n",
        "    def __init__(self, in_dim, kernel_size=4, stride=2):\n",
        "        super(DCGenerator, self).__init__()\n",
        "        self.in_dim = in_dim\n",
        "        self.gen = nn.Sequential(\n",
        "            dc_gen_block(in_dim, 1024, kernel_size, stride),\n",
        "            dc_gen_block(1024, 512, kernel_size, stride),\n",
        "            # Add last generator block\n",
        "            dc_gen_block(512,256, kernel_size, stride),\n",
        "            # Add transposed convolution\n",
        "            nn.ConvTranspose2d(256, 3, kernel_size, stride=stride),\n",
        "            # Add tanh activation\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(len(x), self.in_dim, 1, 1)\n",
        "        return self.gen(x)"
      ],
      "metadata": {
        "id": "xqeHaLySsl1L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convolutional Discriminator\n",
        "With the DCGAN's generator ready, the last step before you can proceed to training it is to define the convolutional discriminator.\n",
        "\n",
        "torch.nn is imported for you under its usual alias. To build the convolutional discriminator, you will use a custom gc_disc_block() function which returns a block of a convolution followed by a batch norm and the leaky ReLU activation. You can inspect dc_disc_block()'s definition below."
      ],
      "metadata": {
        "id": "afacgygytBN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def dc_disc_block(in_dim, out_dim, kernel_size, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(in_dim, out_dim, kernel_size, stride=stride),\n",
        "        nn.BatchNorm2d(out_dim),\n",
        "        nn.LeakyReLU(0.2),\n",
        "    )"
      ],
      "metadata": {
        "id": "9lYqlNJdtCoN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DCDiscriminator(nn.Module):\n",
        "    def __init__(self, kernel_size=4, stride=2):\n",
        "        super(DCDiscriminator, self).__init__()\n",
        "        self.disc = nn.Sequential(\n",
        "          \t# Add first discriminator block\n",
        "            dc_disc_block(3, 512, kernel_size, stride),\n",
        "            dc_disc_block(3, 512, kernel_size, stride),\n",
        "            dc_disc_block(512, 1024, kernel_size, stride),\n",
        "          \t# Add a convolution\n",
        "            nn.Conv2d(1024, 1, kernel_size, stride=stride),\n",
        "            nn.Conv2d(1024, 1, kernel_size, stride=stride),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through sequential block\n",
        "        x = self.disc(x)\n",
        "        return x.view(len(x), -1)"
      ],
      "metadata": {
        "id": "8MEfv1xitFiK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator loss\n",
        "Before you can train your GAN, you need to define loss functions for both the generator and the discriminator. You will start with the former.\n",
        "\n",
        "Recall that the generator's job is to produce such fake images that would fool the discriminator into classifying them as real. Therefore, the generator incurs a loss if the images it generated are classified by the discriminator as fake (label 0).\n",
        "\n",
        "Define the gen_loss() function that calculates the generator loss. It takes four arguments:\n",
        "\n",
        "gen, the generator model\n",
        "disc, the discriminator model\n",
        "num_images, the number of images in batch\n",
        "z_dim, the size of the input random noise"
      ],
      "metadata": {
        "id": "MdB6GvH9ugjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_loss(gen, disc, criterion, num_images, z_dim):\n",
        "    # Define random noise\n",
        "    noise = torch.rand(num_images, z_dim)\n",
        "    # Generate fake image\n",
        "    fake = gen(noise)\n",
        "    # Get discriminator's prediction on the fake image\n",
        "    disc_pred = disc(fake)\n",
        "    # Compute generator loss\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    gen_loss = criterion(disc_pred, torch.ones_like(disc_pred))\n",
        "    return gen_loss"
      ],
      "metadata": {
        "id": "XQsDJYP7ujTa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator loss\n",
        "It's time to define the loss for the discriminator. Recall that the discriminator's job is to classify images either real or fake. Therefore, the generator incurs a loss if it classifies generator's outputs as real (label 1) or the real images as fake (label 0).\n",
        "\n",
        "Define the disc_loss() function that calculates the discriminator loss. It takes five arguments:\n",
        "\n",
        "gen, the generator model\n",
        "disc, the discriminator model\n",
        "real, a sample of real images from the training data\n",
        "num_images, the number of images in batch\n",
        "z_dim, the size of the input random noise"
      ],
      "metadata": {
        "id": "nvcMINUXveq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def disc_loss(gen, disc, real, num_images, z_dim):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    noise = torch.randn(num_images, z_dim)\n",
        "    fake = gen(noise)\n",
        "    # Get discriminator's predictions for fake images\n",
        "    disc_pred_fake = disc(fake)\n",
        "    # Calculate the fake loss component\n",
        "    fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n",
        "    # Get discriminator's predictions for real images\n",
        "    disc_pred_real = disc(real)\n",
        "    # Calculate the real loss component\n",
        "    real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n",
        "    disc_loss = (real_loss + fake_loss) / 2\n",
        "    return disc_loss"
      ],
      "metadata": {
        "id": "xQUqpZ9wuyQI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training loop\n",
        "Finally, all the hard work you put into defining the model architectures and loss functions comes to fruition: it's training time! Your job is to implement and execute the GAN training loop. Note: a break statement is placed after the first batch of data to avoid a long runtime.\n",
        "\n",
        "The two optimizers, disc_opt and gen_opt, have been initialized as Adam() optimizers. The functions to compute the losses that you defined earlier, gen_loss() and disc_loss(), are available to you. A dataloader is also prepared for you.\n",
        "\n",
        "Recall that:\n",
        "\n",
        "disc_loss()'s arguments are: gen, disc, real, cur_batch_size, z_dim.\n",
        "gen_loss()'s arguments are: gen, disc, cur_batch_size, z_dim."
      ],
      "metadata": {
        "id": "DLoNWaX3wj8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "# Assuming 'dataset' is defined and contains your data\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True) # Create a DataLoader instance\n"
      ],
      "metadata": {
        "id": "eQ5J5IOlx0io"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "    for real in dataloader:\n",
        "        cur_batch_size = len(real)\n",
        "\n",
        "        disc_opt.zero_grad()\n",
        "        # Calculate discriminator loss\n",
        "        disc_loss = disc_loss(gen, disc, real, cur_batch_size, 16)\n",
        "        # Compute gradients\n",
        "        disc_loss.backward()\n",
        "        disc_opt.step()\n",
        "\n",
        "        gen_opt.zero_grad()\n",
        "        # Calculate generator loss\n",
        "        gen_loss = gen_loss(gen, disc, cur_batch_size, 16)\n",
        "        # Compute generator gradients\n",
        "        gen_loss.backward()\n",
        "        gen_opt.step()\n",
        "\n",
        "        print(f\"Generator loss: {gen_loss}\")\n",
        "        print(f\"Discriminator loss: {disc_loss}\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "collapsed": true,
        "id": "4FRxQX6owk1y",
        "outputId": "098642bc-dab6-4af8-d157-d680473fc0b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataloader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1d005f9bfcbb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mreal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mcur_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdisc_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating images\n",
        "Now that you have designed and trained your GAN, it's time to evaluate the quality of the images it can generate. For a start, you will perform a visual inspection to see if the generation resemble the Pokemons at all. To do this, you will create random noise as input for the generator, pass it to the model and plot the outputs.\n",
        "\n",
        "The Deep Convolutional Generator with trained weights is available to you as gen. torch and matplotlib.pyplot as plt are already imported for you."
      ],
      "metadata": {
        "id": "pVHkR4vUy_oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "Mop30R_30e8p"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_images_to_generate = 5\n",
        "# Create random noise tensor\n",
        "noise =  torch.randn(num_images_to_generate, 16)\n",
        "\n",
        "# Generate images\n",
        "with torch.no_grad():\n",
        "    fake = gen(noise)\n",
        "print(f\"Generated tensor shape: {fake.shape}\")\n",
        "\n",
        "for i in range(num_images_to_generate):\n",
        "    # Slice fake to select i-th image\n",
        "    image_tensor = fake[i, :,:,:]\n",
        "    # Permute the image dimensions\n",
        "    image_tensor_permuted = image_tensor.permute(1,2,0)\n",
        "    plt.imshow(image_tensor_permuted)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "collapsed": true,
        "id": "DADuN0FjycBy",
        "outputId": "8c9bd45b-99e3-4d66-9cf7-ddd720eb58e4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gen' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9883e055d134>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Generate images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generated tensor shape: {fake.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gen' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fréchet Inception Distance\n",
        "The visual inspection of generated images is a great start. But given they look okay, a more precise, quantitative evaluation will be helpful to understand the generator's performance. You will evaluate your GAN using the Fréchet Inception Distance, or FID.\n",
        "\n",
        "Two tensors with fake and real images, 32 examples each, are available to you as fake and real, respectively. Use them to compute the FID!"
      ],
      "metadata": {
        "id": "Da32fp5X0zAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import FrechetInceptionDistance\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "\n",
        "# Instantiate FID\n",
        "fid = FrechetInceptionDistance(feature=64)\n",
        "\n",
        "\n",
        "# Update FID with real images\n",
        "fid.update((fake * 255).to(torch.uint8), real=False)\n",
        "fid.update((real * 255).to(torch.uint8), real=True)\n",
        "\n",
        "# Compute the metric\n",
        "fid_score = fid.compute()\n",
        "print(fid_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "collapsed": true,
        "id": "IZmnS4Bg0z26",
        "outputId": "394fba3f-f2d8-44de-e12f-a3bb6237c1b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torchmetrics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-757328dcad88>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Import FrechetInceptionDistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFrechetInceptionDistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Instantiate FID\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrechetInceptionDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchmetrics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mAH6I7y4y_Ba"
      }
    }
  ]
}